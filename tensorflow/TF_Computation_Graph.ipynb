{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "matplotlib.rcParams['figure.dpi'] = 144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- requirement: small_data/cal_house.json.gz -->\n",
    "# Optimization with the Computation Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow is supposed to be optimized for the mathematical operations common in machine learning. Let's benchmark the two linear regression classes from the [TF_Intro_TensorFlow](TF_Intro_TensorFlow.ipynb) notebook, one of which is based on NumPy and one of which is based on TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionNP():\n",
    "    def __init__(self, eta=.1):\n",
    "        self.W = 0\n",
    "        self.b = 0\n",
    "        self.eta = eta\n",
    "    \n",
    "    def loss(self, X, y):\n",
    "        return ((X * self.W + self.b - y) ** 2).mean()\n",
    "    \n",
    "    def _gradients(self, X, y):\n",
    "        return {'W': (2 * X * (X * self.W + self.b - y)).mean(),\n",
    "                'b': (2 * (X * self.W + self.b - y)).mean()}\n",
    "        \n",
    "    def fit(self, X, y, steps=10):\n",
    "        for _ in range(steps):\n",
    "            gradients = self._gradients(X, y)\n",
    "            self.W = self.W - self.eta * gradients['W']\n",
    "            self.b = self.b - self.eta * gradients['b']\n",
    "            \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionTF():\n",
    "    def __init__(self, eta=.1):\n",
    "        self.W = tf.Variable(0.)\n",
    "        self.b = tf.Variable(0.)\n",
    "        self.opt = tf.keras.optimizers.SGD(learning_rate=eta)\n",
    "    \n",
    "    def loss(self, X, y, return_func=False):\n",
    "        def loss_():\n",
    "            return tf.reduce_mean(tf.square(X * self.W + self.b - y))\n",
    "        \n",
    "        if not return_func:\n",
    "            return loss_()\n",
    "        \n",
    "        return loss_\n",
    "    \n",
    "    def fit(self, X, y, steps=10):\n",
    "        for _ in range(steps):\n",
    "            self.opt.minimize(self.loss(X, y, return_func=True), [self.W, self.b])\n",
    "            \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_model = LinearRegressionNP()\n",
    "tf_model = LinearRegressionTF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "with gzip.open(\"small_data/cal_house.json.gz\", \"r\") as fin:\n",
    "    housing = json.load(fin)\n",
    "    \n",
    "for train, test in ShuffleSplit(1, 0.2, random_state=42).split(housing['data']):\n",
    "    X_train = np.array(housing['data'])[train].astype(np.float32)\n",
    "    y_train = np.array(housing['target'])[train].astype(np.float32)\n",
    "    X_test = np.array(housing['data'])[test].astype(np.float32)\n",
    "    y_test = np.array(housing['target'])[test].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "np_model.fit(X_train[:, 0:1], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "tf_model.fit(X_train[:, 0:1], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NumPy model is faster (slightly) than the TensorFlow model! What's going on here?\n",
    "\n",
    "TensorFlow's computational advantage comes in two forms:\n",
    "\n",
    "1. Making use of a computational graph. The graph is compiled, allowing for fast execution.\n",
    "2. TensorFlow can place computations on hardware accelerators (GPUs, TPUs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow can record tensors and operations on them in a data structure called a computation graph. This graph can be compiled before runtime for faster execution (e.g. operations can be parallelized based on analysis of the graph during compilation). The graph also enables TensorFlow to compute gradients more directly since the results of operations don't have to be accumulated as they are executed. \n",
    "\n",
    "In TensorFlow 2.0 we mark which computations should be entered into the graph using the `tf.function` decorator. In TensorFlow 1.x, all computation was accomplished through the computation graph. To contrast these two approaches, the graph generated by `tf.function` is sometimes referred to as the [autograph](https://www.tensorflow.org/beta/guide/autograph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(W, b, X, y):\n",
    "    return tf.reduce_mean(tf.square(X * W + b - y))\n",
    "    \n",
    "def gradients(W, b, X, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = mse(W, b, X, y)\n",
    "        \n",
    "    return tape.gradient(loss, [W, b])\n",
    "\n",
    "@tf.function\n",
    "def gradients_fn(W, b, X, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = mse(W, b, X, y)\n",
    "        \n",
    "    return tape.gradient(loss, [W, b])\n",
    "\n",
    "X = tf.random.uniform((10000, 1))\n",
    "y = tf.random.uniform((10000, 1))\n",
    "W = tf.Variable(0.)\n",
    "b = tf.Variable(0.)\n",
    "\n",
    "assert tf.math.reduce_all(tf.equal(gradients(W, b, X, y), gradients_fn(W, b, X, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "gradients(W, b, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "gradients_fn(W, b, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the graph is compiled at the time of the first function call (known as just-in-time, JIT, compilation). We only realize faster computation upon subsequent function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "@tf.function\n",
    "def gradients_fn(W, b, X, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = mse(W, b, X, y)\n",
    "        \n",
    "    return tape.gradient(loss, [W, b])\n",
    "\n",
    "start = time.time()\n",
    "gradients_fn(W, b, X, y)\n",
    "print(\"Time elapsed on first call: {}\".format(time.time() - start))\n",
    "\n",
    "start = time.time()\n",
    "gradients_fn(W, b, X, y)\n",
    "print(\"Time elapsed on second call: {}\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, compilation takes place any time the arguments different in `shape` or `dtype` from the previous arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 100\n",
    "\n",
    "start = time.time()\n",
    "gradients_fn(W, b, X[:i], y[:i])\n",
    "print(\"Time elapsed on first call: {}\".format(time.time() - start))\n",
    "\n",
    "start = time.time()\n",
    "gradients_fn(W, b, X[:i], y[:i])\n",
    "print(\"Time elapsed on second call: {}\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that we typically want to supply a `tf.function` with tensors (or NumPy arrays) as arguments. Python native types do not have `shape` or `dtype` information, and therefore the graph will be recompiled any time the values change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def gradients_fn(W, b, X, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = mse(W, b, X, y)\n",
    "        \n",
    "    return tape.gradient(loss, [W, b])\n",
    "\n",
    "X_np = np.random.random((10000, 1)).astype(np.float32).tolist()\n",
    "y_np = np.random.random((10000, 1)).astype(np.float32).tolist()\n",
    "\n",
    "start = time.time()\n",
    "gradients_fn(W, b, X_np, y_np)\n",
    "print(\"Time elapsed on first call: {}\".format(time.time() - start))\n",
    "\n",
    "# UNCOMMENT TO CONTRAST\n",
    "# X_np = np.random.random((10000, 1)).astype(np.float32).tolist()\n",
    "# y_np = np.random.random((10000, 1)).astype(np.float32).tolist()\n",
    "\n",
    "start = time.time()\n",
    "gradients_fn(W, b, X_np, y_np)\n",
    "print(\"Time elapsed on second call: {}\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Optimize `LinearRegressionTF`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `tf.function` to optimize `LinearRegressionTF`. Demonstrate that the `LinearRegressionTF.fit` runs faster than `LinearRegressionNP.fit`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using accelerators (GPUs/TPUs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making use of GPUs requires additional drivers and libraries that are not packaged with TensorFlow by default. Instead of installing `tensorflow` (which is installed in this environment) with your package manager, you would install `tensorflow-gpu`. Furthermore, your machine must have the compatible hardware, which you can check in TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TensorFlow built with GPU support: {}'.format(tf.test.is_built_with_cuda()))\n",
    "print('Compatible GPU installed: {}'.format(tf.test.is_gpu_available()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each tensor and operation has a device attribute that describes what hardware is responsible for its evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow will automatically preferentially place operations with GPU implementations on GPUs. If you need to exercise more manual control, TensorFlow provides a context manager for controlling on what device a tensor or operation resides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    on_cpu = tf.constant([[1, 2,], [3, 4]])\n",
    "    \n",
    "on_cpu.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately due to limitations of the environment, we only have one device available for demonstrating this facet of TensorFlow, but you can [read more about this capability in the TensorFlow documentation](https://www.tensorflow.org/beta/guide/using_gpu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright &copy; 2019 Pragmatic Institute. This content is licensed solely for personal use. Redistribution or publication of this material is strictly prohibited.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
